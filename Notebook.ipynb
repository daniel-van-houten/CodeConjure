{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Setup Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.schema import BaseOutputParser, ChatResult\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents.conversational.prompt import FORMAT_INSTRUCTIONS\n",
    "import re\n",
    "import json\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "class NewAgentOutputParser(BaseOutputParser):\n",
    "    def get_format_instructions(self) -> str:\n",
    "        return FORMAT_INSTRUCTIONS\n",
    "\n",
    "    def parse(self, text: str) -> Any:\n",
    "        print(\"-\" * 20)\n",
    "        cleaned_output = text.strip()\n",
    "        # Regex patterns to match action and action_input\n",
    "        action_pattern = r'\"action\":\\s*\"([^\"]*)\"'\n",
    "        action_input_pattern = r'\"action_input\":\\s*\"([^\"]*)\"'\n",
    "\n",
    "        # Extracting first action and action_input values\n",
    "        action = re.search(action_pattern, cleaned_output)\n",
    "        action_input = re.search(action_input_pattern, cleaned_output)\n",
    "\n",
    "        if action:\n",
    "            action_value = action.group(1)\n",
    "            print(f\"First Action: {action_value}\")\n",
    "        else:\n",
    "            print(\"Action not found\")\n",
    "\n",
    "        if action_input:\n",
    "            action_input_value = action_input.group(1)\n",
    "            print(f\"First Action Input: {action_input_value}\")\n",
    "        else:\n",
    "            print(\"Action Input not found\")\n",
    "\n",
    "        print(\"-\" * 20)\n",
    "        if action_value and action_input_value:\n",
    "            return {\"action\": action_value, \"action_input\": action_input_value}\n",
    "\n",
    "        # Problematic code left just in case\n",
    "        if \"```json\" in cleaned_output:\n",
    "            _, cleaned_output = cleaned_output.split(\"```json\")\n",
    "        if \"```\" in cleaned_output:\n",
    "            cleaned_output, _ = cleaned_output.split(\"```\")\n",
    "        if cleaned_output.startswith(\"```json\"):\n",
    "            cleaned_output = cleaned_output[len(\"```json\"):]\n",
    "        if cleaned_output.startswith(\"```\"):\n",
    "            cleaned_output = cleaned_output[len(\"```\"):]\n",
    "        if cleaned_output.endswith(\"```\"):\n",
    "            cleaned_output = cleaned_output[: -len(\"```\")]\n",
    "        cleaned_output = cleaned_output.strip()\n",
    "        response = json.loads(cleaned_output)\n",
    "        return {\"action\": response[\"action\"], \"action_input\": response[\"action_input\"]}\n",
    "        # end of problematic code\n",
    "    \n",
    "    \n",
    "def extract_file_paths(directory_structure, extensions=None):\n",
    "    lines = directory_structure.split('\\n')\n",
    "    paths = []\n",
    "    stack = []\n",
    "\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        depth = line.count('  ')\n",
    "        filename = line.strip(' -')\n",
    "\n",
    "        while depth <= len(stack) - 1:\n",
    "            stack.pop()\n",
    "\n",
    "        if '.' in filename and (not extensions or filename.split('.')[-1] in extensions):\n",
    "            file_path = '/'.join(stack + [filename])\n",
    "            paths.append(file_path)\n",
    "        else:\n",
    "            stack.append(filename)\n",
    "\n",
    "    return paths\n",
    "\n",
    "def get_chat_result_text(result:ChatResult):\n",
    "    return result.generations[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Describe the Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MESSAGE = \"\"\"You're an expert software engineer specializing in Azure and .NET development. You can generate complete production-ready \n",
    "code examples complete with xml comments and helpful code comments. Your code quality is very readable on its own, but where increased \n",
    "complexity is present you also add in code comments. Unit testable via dependency injection should be considered. \n",
    "While you have deep knowledge of best practices, you realize that sometimes real-world practicality outweighs academics.\"\"\"   \n",
    "\n",
    "PROJECT_DESCIPTION=\"\"\"I'd like to create a service which will fetch an object from S3 storage, parse it (it will contain 20K rows), \n",
    "and populate a supabase table with the data. The data represents a list of simple products and their attributes. The object is a json file.\n",
    "Once the data is in the supabase table, I need to send an email letting \"john@biz.com\" know the data has been loaded. \n",
    "I also need to create a simple API endpoint which will allow me to search the table by product name.\n",
    "\"\"\"\n",
    "\n",
    "PROJECT_STYLE=\"\"\"Follow SOLID principals. \n",
    "Add xml comments to all public methods and classes. \n",
    "Components should be loosely coupled and follow the layered architecture.\n",
    "Dependency Injection is very important.\n",
    "There should be a single solution file which contains all .NET Core projects.\n",
    "Use Nuget packages where appropriate to reduce custom code.\n",
    "Do Not Generate Tests. I will write my own tests.\n",
    "\"\"\"\n",
    "\n",
    "DIRECTORY_STRUCTURE_EXAMPLE = \"\"\"Here is an example of the format I'm looking for:\n",
    "- MainProject.Services\n",
    "  - Interfaces\n",
    "    - IServiceA.cs\n",
    "  - Services\n",
    "    - ServiceA.cs\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Generate the project structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import StringPromptTemplate, ChatMessagePromptTemplate\n",
    "from pydantic import BaseModel, validator\n",
    "\n",
    "class CodeProjectOutlinePromptTemplate(StringPromptTemplate, BaseModel):\n",
    "    \n",
    "    def __init__(self, **data):\n",
    "        super().__init__(**data)\n",
    "        \n",
    "    \"\"\" A custom prompt template that takes in code project information and proposes a file structure \"\"\"\n",
    "\n",
    "    @validator(\"input_variables\")\n",
    "    def validate_input_variables(cls, v):\n",
    "        \"\"\" Validate that the input variables are correct. \"\"\"\n",
    "        if len(v) != 1 or \"project_description\" not in v:\n",
    "            raise ValueError(\"function_name must be the only input_variable.\")\n",
    "        return v\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Generate the prompt to be sent to the language model\n",
    "        prompt = f\"\"\"\n",
    "{kwargs[\"project_description\"]}\n",
    "Show me the complete directory structure containing the code files necessary to meet the described need. Do not explain. Do not generate tests files.\n",
    "Output nothing but the directory structure.\n",
    "\n",
    "Here is an example of the output format I'm looking for:\n",
    "- ParentDirectory\n",
    "  - ChildDirectory\n",
    "    - ChildFile\n",
    "- ParentDirectory\n",
    "    - ChildFile\n",
    "\n",
    "Output nothing but the directory structure in plain text.\n",
    "\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def _prompt_type(self):\n",
    "        return \"project-file-structure\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "\n",
    "# gpt-3.5-turbo | gpt-4\n",
    "llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", max_tokens=2048, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following until it produces something you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "project_outline_prompt_template = CodeProjectOutlinePromptTemplate(input_variables=[\"project_description\"])\n",
    "project_outline_prompt = project_outline_prompt_template.format(project_description=f\"{PROJECT_DESCIPTION}\\n\\n{PROJECT_STYLE}\")\n",
    "\n",
    "response = llm._generate(messages=[HumanMessage(content=project_outline_prompt)])\n",
    "\n",
    "project_outline = get_chat_result_text(response)\n",
    "print(project_outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "WORKING_DIRECTORY = \"./sandbox\"\n",
    "\n",
    "files_paths = extract_file_paths(project_outline, [\"cs\"])\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=SYSTEM_MESSAGE),\n",
    "    HumanMessage(content=project_outline_prompt),\n",
    "    AIMessage(content=project_outline)\n",
    "]\n",
    "\n",
    "# Code is usually presented with markdown code blocks even when asked to exclude them. \n",
    "# We need to remove these.\n",
    "code_markdown_pattern = r\"(?<!\\\\)```(?:[a-z]+\\n)?|\\n?```(?<!\\\\)\"\n",
    "\n",
    "# clean workspace\n",
    "if(os.path.exists(WORKING_DIRECTORY)):\n",
    "    print('sandbox exists. deleting...')\n",
    "    shutil.rmtree(WORKING_DIRECTORY)\n",
    "    \n",
    "\n",
    "for file_path in files_paths[:8]:\n",
    "    print(file_path)\n",
    "    sandbox_path = os.path.join(WORKING_DIRECTORY, file_path)\n",
    "    os.makedirs(os.path.dirname(sandbox_path), exist_ok=True)\n",
    "    \n",
    "    code_prompt = HumanMessage(content=\"Show me the code for: \" + file_path + \".\\n\\nOutput only the code in plain text, no markdown or explanations.\")\n",
    "    \n",
    "    temp_messages = messages.copy()\n",
    "    temp_messages.append(code_prompt)\n",
    "    \n",
    "    result = llm._generate(messages=temp_messages)\n",
    "    code = get_chat_result_text(result)\n",
    "    code = re.sub(code_markdown_pattern, \"\", code)\n",
    "    \n",
    "    with open(sandbox_path, 'w') as f:\n",
    "        f.write(code)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
